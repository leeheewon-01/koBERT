{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e4cc85",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install ipywidgets\n",
    "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e19175",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/SKTBrain/KoBERT.git\n",
    "%cd KoBERT\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55941fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6386bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kobert import get_tokenizer\n",
    "from kobert import get_pytorch_kobert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a61538cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9febe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09b3f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80d23b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = nlp.data.TSVDataset(\".cache/ratings_train.txt\", field_indices=[1,2], num_discard_samples=1)\n",
    "dataset_test = nlp.data.TSVDataset(\".cache/ratings_test.txt\", field_indices=[1,2], num_discard_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b876901",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f9c6c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ff68ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 5\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e32e5efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dc316f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=0)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ae0038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=2,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        else:\n",
    "            out = pooler\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b4b045b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df4e029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "805237cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "342e2860",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a31abb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65d9fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b26aeb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010963201522827148,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2344,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5365b8cb4564edb8907593babe27ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2344 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 0.7051867842674255 train acc 0.578125\n",
      "epoch 1 batch id 201 loss 0.5161126852035522 train acc 0.5763370646766169\n",
      "epoch 1 batch id 401 loss 0.4631495773792267 train acc 0.6867206982543641\n",
      "epoch 1 batch id 601 loss 0.4288637638092041 train acc 0.73681884359401\n",
      "epoch 1 batch id 801 loss 0.40208566188812256 train acc 0.7654299313358303\n",
      "epoch 1 batch id 1001 loss 0.32055723667144775 train acc 0.7820772977022977\n",
      "epoch 1 batch id 1201 loss 0.3071320354938507 train acc 0.7947283513738551\n",
      "epoch 1 batch id 1401 loss 0.36454036831855774 train acc 0.8040796752319772\n",
      "epoch 1 batch id 1601 loss 0.32095015048980713 train acc 0.8116118831980013\n",
      "epoch 1 batch id 1801 loss 0.27967509627342224 train acc 0.8179223348139922\n",
      "epoch 1 batch id 2001 loss 0.26608070731163025 train acc 0.8235569715142429\n",
      "epoch 1 batch id 2201 loss 0.2806864380836487 train acc 0.8281675942753294\n",
      "epoch 1 train acc 0.8315246373720137\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008969783782958984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 782,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8528674dee114fcda64fb553f8ff20f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 test acc 0.8827725383631714\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00797271728515625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2344,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc4696f0beb48cfb3a439f0c8f93f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2344 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.43884941935539246 train acc 0.8125\n",
      "epoch 2 batch id 201 loss 0.24372044205665588 train acc 0.880752487562189\n",
      "epoch 2 batch id 401 loss 0.24569550156593323 train acc 0.8828709476309227\n",
      "epoch 2 batch id 601 loss 0.3707982301712036 train acc 0.8861012895174709\n",
      "epoch 2 batch id 801 loss 0.41161099076271057 train acc 0.8889864232209738\n",
      "epoch 2 batch id 1001 loss 0.25685617327690125 train acc 0.8913118131868132\n",
      "epoch 2 batch id 1201 loss 0.2036823034286499 train acc 0.8934871981681932\n",
      "epoch 2 batch id 1401 loss 0.21629850566387177 train acc 0.8955545146324054\n",
      "epoch 2 batch id 1601 loss 0.27985796332359314 train acc 0.8975933010618363\n",
      "epoch 2 batch id 1801 loss 0.18193812668323517 train acc 0.8993874930594115\n",
      "epoch 2 batch id 2001 loss 0.22241535782814026 train acc 0.9013305847076462\n",
      "epoch 2 batch id 2201 loss 0.24903827905654907 train acc 0.9026649818264425\n",
      "epoch 2 train acc 0.9041435580204779\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008704900741577148,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 782,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62fc10baee84c8182303754469b69d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 test acc 0.8875479539641944\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009162425994873047,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2344,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca429b32867458babfc8c0fa650bb2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2344 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 0.4762604236602783 train acc 0.78125\n",
      "epoch 3 batch id 201 loss 0.12035330384969711 train acc 0.9224191542288557\n",
      "epoch 3 batch id 401 loss 0.12307340651750565 train acc 0.9232387780548629\n",
      "epoch 3 batch id 601 loss 0.23800422251224518 train acc 0.9247348169717138\n",
      "epoch 3 batch id 801 loss 0.2605189383029938 train acc 0.9281171972534332\n",
      "epoch 3 batch id 1001 loss 0.24368125200271606 train acc 0.9308503996003996\n",
      "epoch 3 batch id 1201 loss 0.10843860357999802 train acc 0.9328164029975021\n",
      "epoch 3 batch id 1401 loss 0.14469993114471436 train acc 0.9348456459671663\n",
      "epoch 3 batch id 1601 loss 0.18491841852664948 train acc 0.9361434259837601\n",
      "epoch 3 batch id 1801 loss 0.09871844947338104 train acc 0.9375086757357024\n",
      "epoch 3 batch id 2001 loss 0.12353959679603577 train acc 0.9389914417791104\n",
      "epoch 3 batch id 2201 loss 0.1502556949853897 train acc 0.9401124488868696\n",
      "epoch 3 train acc 0.9411085039817976\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008970022201538086,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 782,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13dad541f1d408ca917d63988369dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 test acc 0.8960597826086957\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009966850280761719,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2344,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a421f44642ba4663a81f77e1be3eca1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2344 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 0.45969119668006897 train acc 0.875\n",
      "epoch 4 batch id 201 loss 0.12929657101631165 train acc 0.9556902985074627\n",
      "epoch 4 batch id 401 loss 0.09087707847356796 train acc 0.9560084164588528\n",
      "epoch 4 batch id 601 loss 0.1462012529373169 train acc 0.9576227121464226\n",
      "epoch 4 batch id 801 loss 0.22026221454143524 train acc 0.9592696629213483\n",
      "epoch 4 batch id 1001 loss 0.16651025414466858 train acc 0.9607111638361638\n",
      "epoch 4 batch id 1201 loss 0.05518503859639168 train acc 0.9618156744379683\n",
      "epoch 4 batch id 1401 loss 0.04202696681022644 train acc 0.9627052105638829\n",
      "epoch 4 batch id 1601 loss 0.1369001865386963 train acc 0.9631773110555902\n",
      "epoch 4 batch id 1801 loss 0.07772617787122726 train acc 0.9641258328706275\n",
      "epoch 4 batch id 2001 loss 0.06766048818826675 train acc 0.9650331084457772\n",
      "epoch 4 batch id 2201 loss 0.1497439593076706 train acc 0.9656406179009541\n",
      "epoch 4 train acc 0.9661436113481229\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00996708869934082,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 782,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232d4bf25e71454d934052d53faa554a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 test acc 0.8975983056265985\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009966135025024414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2344,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31de93dd978a41c99665fba347f4a474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2344 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 0.4718216359615326 train acc 0.875\n",
      "epoch 5 batch id 201 loss 0.036575496196746826 train acc 0.9738028606965174\n",
      "epoch 5 batch id 401 loss 0.05199874937534332 train acc 0.9753740648379052\n",
      "epoch 5 batch id 601 loss 0.13261984288692474 train acc 0.9757955490848585\n",
      "epoch 5 batch id 801 loss 0.20332427322864532 train acc 0.9762796504369539\n",
      "epoch 5 batch id 1001 loss 0.041516054421663284 train acc 0.977022977022977\n",
      "epoch 5 batch id 1201 loss 0.015168735757470131 train acc 0.977583784346378\n",
      "epoch 5 batch id 1401 loss 0.04586707800626755 train acc 0.9776275874375446\n",
      "epoch 5 batch id 1601 loss 0.040245287120342255 train acc 0.9777873204247346\n",
      "epoch 5 batch id 1801 loss 0.00872697215527296 train acc 0.9780764158800667\n",
      "epoch 5 batch id 2001 loss 0.04306286200881004 train acc 0.9784873188405797\n",
      "epoch 5 batch id 2201 loss 0.10302364826202393 train acc 0.978546683325761\n",
      "epoch 5 train acc 0.9786556100682594\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010963201522827148,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 782,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105eb501f53d45d0b4679bd62dbd0f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 test acc 0.8977781329923273\n"
     ]
    }
   ],
   "source": [
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "557cf28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 위에서 설정한 tok, max_len, batch_size, device를 그대로 입력\n",
    "# comment : 예측하고자 하는 텍스트 데이터 리스트\n",
    "def getSentimentValue(comment, tok, max_len, batch_size, device):\n",
    "  commnetslist = [] # 텍스트 데이터를 담을 리스트\n",
    "  emo_list = [] # 감성 값을 담을 리스트\n",
    "  for c in comment: # 모든 댓글\n",
    "    commnetslist.append( [c, 5] ) # [댓글, 임의의 양의 정수값] 설정\n",
    "    \n",
    "  pdData = pd.DataFrame( commnetslist, columns = [['댓글', '감성']] )\n",
    "  pdData = pdData.values\n",
    "  test_set = BERTDataset(pdData, 0, 1, tok, max_len, True, False) \n",
    "  test_input = torch.utils.data.DataLoader(test_set, batch_size=batch_size, num_workers=0)\n",
    "  \n",
    "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_input):\n",
    "    token_ids = token_ids.long().to(device)\n",
    "    segment_ids = segment_ids.long().to(device)\n",
    "    valid_length= valid_length \n",
    "    # 이때, out이 예측 결과 리스트\n",
    "    out = model(token_ids, valid_length, segment_ids)\n",
    "\t\n",
    "    # e는 2가지 실수 값으로 구성된 리스트\n",
    "    # 0번 인덱스가 더 크면 부정, 긍정은 반대\n",
    "    for e in out:\n",
    "      if e[0]>e[1]: # 부정\n",
    "        value = 0\n",
    "      else: #긍정\n",
    "        value = 1\n",
    "      emo_list.append(value)\n",
    "\n",
    "  return emo_list # 텍스트 데이터에 1대1 매칭되는 감성값 리스트 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "186d300c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = ['완전 좋아',\n",
    "'너무하네','최고야']\n",
    "getSentimentValue(comment, tok, max_len, batch_size, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
